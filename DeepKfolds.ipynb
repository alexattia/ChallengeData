{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T16:46:51.863651Z",
     "start_time": "2018-03-25T16:46:50.973805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexattia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import feat_eng\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T16:50:10.066246Z",
     "start_time": "2018-03-25T16:46:54.004809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1439/1439 [00:16<00:00, 89.42it/s]\n",
      "100%|██████████| 1440/1440 [01:04<00:00, 22.21it/s]\n",
      "100%|██████████| 1440/1440 [00:19<00:00, 72.23it/s]\n",
      "100%|██████████| 1440/1440 [01:05<00:00, 21.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "label = pd.read_csv('./challenge_output_data_training_file_nba_challenge.csv', sep=';')\n",
    "train = pd.merge(train, label, on='ID')\n",
    "\n",
    "train = feat_eng.add_fg(train)\n",
    "train = feat_eng.add_incremental_features(train)\n",
    "\n",
    "#df_train, df_val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "#print(df_train.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T16:51:16.162950Z",
     "start_time": "2018-03-25T16:51:14.040668Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train.label.values\n",
    "X = train.drop(['ID', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-25T16:37:59.120Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "#kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:02:42.722080Z",
     "start_time": "2018-03-25T16:51:19.141134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train pivotation 1440/1441Train table pivoted\n"
     ]
    }
   ],
   "source": [
    "df1 = train\n",
    "df1_tot = pd.DataFrame()\n",
    "for sec in range(1,1441):\n",
    "    print('\\r Train pivotation %d/%d' % (sec, 1441), end='')\n",
    "    df_sec = df1[['ID', 'label']+[k for k in df1.columns if k not in ['label', 'ID'] and k.split('_')[1] == str(sec)]]\n",
    "    df_sec.columns = [k.split('_')[0] if k not in ['ID', 'time_step', 'label'] else k for k in df_sec.columns]\n",
    "    df_sec = df_sec.assign(time_step = sec)\n",
    "    df1_tot = pd.concat([df1_tot, df_sec])\n",
    "df1_tot = df1_tot.sort_values(['ID', 'time_step'])\n",
    "print('Train table pivoted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:02:46.833035Z",
     "start_time": "2018-03-25T17:02:46.827835Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['score', 'offensive rebound', 'defensive rebound',\n",
    "        'offensive foul', 'defensive foul', 'assist', 'lost ball', \n",
    "        'steals', 'bad pass', 'block', 'miss', 'two pts', 'three pts', \n",
    "        'fg', 'total rebound', 'turnover', 'fga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:06:31.612608Z",
     "start_time": "2018-03-25T17:02:48.890370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train created\n"
     ]
    }
   ],
   "source": [
    "df_X = df1_tot[df1_tot.time_step < 1441]\n",
    "X = []\n",
    "y = df_X.groupby('ID').mean()['label'].values\n",
    "y = y.reshape((len(y), 1))\n",
    "for id_ in df1_tot.ID.unique():\n",
    "    X.append(df_X[df_X.ID == id_][cols].values)\n",
    "X = np.array(X)\n",
    "print('X_train created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:06:33.498600Z",
     "start_time": "2018-03-25T17:06:32.259645Z"
    }
   },
   "outputs": [],
   "source": [
    "#import run_lstm\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import BatchNormalization, Conv2D, Reshape, LSTM,Bidirectional, Dropout, Dense, TimeDistributed, Lambda, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:06:34.040530Z",
     "start_time": "2018-03-25T17:06:33.552891Z"
    }
   },
   "outputs": [],
   "source": [
    "def deepconvlstm(num_classes):\n",
    "    nb_timestep = 1440\n",
    "    nb_features = 17\n",
    "\n",
    "    my_model = Sequential()\n",
    "\n",
    "    my_model.add(BatchNormalization(input_shape = (nb_timestep,nb_features)))\n",
    "    my_model.add(Reshape([nb_timestep,nb_features,1]))\n",
    "    my_model.add(Conv2D(64, 1,activation=\"relu\"))\n",
    "    my_model.add(MaxPool2D(2))\n",
    "    my_model.add(BatchNormalization())\n",
    "    my_model.add(Conv2D(64,1,activation=\"relu\"))\n",
    "    my_model.add(MaxPool2D(2))\n",
    "    my_model.add(BatchNormalization())\n",
    "    my_model.add(Reshape([int(nb_timestep/4), 3*64]))\n",
    "    my_model.add(LSTM(128, return_sequences=True))\n",
    "    my_model.add(LSTM(128,return_sequences=True))\n",
    "    my_model.add(Dropout(0.2))\n",
    "    my_model.add(TimeDistributed(Dense(2,activation=\"sigmoid\", kernel_regularizer=l2(0.0001))))\n",
    "    my_model.add(Lambda(lambda x: x[:, -1, :], output_shape=[num_classes]))\n",
    "    my_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "    print(\"Model DeepConvLSTM created\")\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:06:34.203213Z",
     "start_time": "2018-03-25T17:06:34.044875Z"
    }
   },
   "outputs": [],
   "source": [
    "def bidirectional_lstm(num_classes):\n",
    "    nb_timestep = 1440\n",
    "    nb_features = 17\n",
    "\n",
    "    my_model = Sequential()\n",
    "    my_model.add(BatchNormalization(input_shape = (nb_timestep,nb_features)))\n",
    "    my_model.add(Bidirectional(LSTM(128, return_sequences=False), merge_mode='concat'))\n",
    "    #print(my_model.layers[-1].output_shape)\n",
    "    my_model.add(Dropout(0.2))\n",
    "    my_model.add(Dense(1,activation=\"sigmoid\", kernel_regularizer=l2(0.0001))) #TimeDistributed(\n",
    "    #print(my_model.layers[-1].output_shape)\n",
    "    my_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "    #my_model.summary()\n",
    "    print(\"Model DeepConvLSTM created\")\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:06:44.567054Z",
     "start_time": "2018-03-25T17:06:34.216897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T15:55:48.715290Z",
     "start_time": "2018-03-25T14:52:30.621527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 1440, 17)          68        \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               149504    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 149,829\n",
      "Trainable params: 149,795\n",
      "Non-trainable params: 34\n",
      "_________________________________________________________________\n",
      "Model DeepConvLSTM created\n",
      "Train on 10061 samples, validate on 2515 samples\n",
      "Epoch 1/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5779 - acc: 0.6950 - val_loss: 0.5486 - val_acc: 0.7145\n",
      "Epoch 2/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5440 - acc: 0.7178 - val_loss: 0.5450 - val_acc: 0.7153\n",
      "Epoch 3/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5385 - acc: 0.7216 - val_loss: 0.5437 - val_acc: 0.7205\n",
      "Epoch 4/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5359 - acc: 0.7216 - val_loss: 0.5444 - val_acc: 0.7141\n",
      "Epoch 5/5\n",
      "10061/10061 [==============================] - 250s 25ms/step - loss: 0.5329 - acc: 0.7273 - val_loss: 0.5444 - val_acc: 0.7121\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 1440, 17)          68        \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               149504    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 149,829\n",
      "Trainable params: 149,795\n",
      "Non-trainable params: 34\n",
      "_________________________________________________________________\n",
      "Model DeepConvLSTM created\n",
      "Train on 10061 samples, validate on 2515 samples\n",
      "Epoch 1/5\n",
      "10061/10061 [==============================] - 252s 25ms/step - loss: 0.5790 - acc: 0.6969 - val_loss: 0.5476 - val_acc: 0.7233\n",
      "Epoch 2/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5454 - acc: 0.7177 - val_loss: 0.5384 - val_acc: 0.7252\n",
      "Epoch 3/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5414 - acc: 0.7184 - val_loss: 0.5346 - val_acc: 0.7245\n",
      "Epoch 4/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5375 - acc: 0.7223 - val_loss: 0.5326 - val_acc: 0.7304\n",
      "Epoch 5/5\n",
      "10061/10061 [==============================] - 252s 25ms/step - loss: 0.5364 - acc: 0.7241 - val_loss: 0.5303 - val_acc: 0.7304\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 1440, 17)          68        \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 256)               149504    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 149,829\n",
      "Trainable params: 149,795\n",
      "Non-trainable params: 34\n",
      "_________________________________________________________________\n",
      "Model DeepConvLSTM created\n",
      "Train on 10061 samples, validate on 2515 samples\n",
      "Epoch 1/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5710 - acc: 0.7012 - val_loss: 0.5370 - val_acc: 0.7304\n",
      "Epoch 2/5\n",
      "10061/10061 [==============================] - 250s 25ms/step - loss: 0.5439 - acc: 0.7187 - val_loss: 0.5327 - val_acc: 0.7340\n",
      "Epoch 3/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5416 - acc: 0.7202 - val_loss: 0.5312 - val_acc: 0.7304\n",
      "Epoch 4/5\n",
      "10061/10061 [==============================] - 251s 25ms/step - loss: 0.5390 - acc: 0.7211 - val_loss: 0.5307 - val_acc: 0.7340\n",
      "Epoch 5/5\n",
      "10061/10061 [==============================] - 252s 25ms/step - loss: 0.5367 - acc: 0.7229 - val_loss: 0.5314 - val_acc: 0.7292\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#dic = {}\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    num_classes = y_train.shape[1]\n",
    "    d = bidirectional_lstm(num_classes)\n",
    "    d.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1, validation_data=(X_val, y_val))\n",
    "    d.save('./lstm_models/bidirec_model_%d' % i)\n",
    "    del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T15:56:14.478030Z",
     "start_time": "2018-03-25T15:55:59.005644Z"
    }
   },
   "outputs": [],
   "source": [
    "model_0 = load_model('./lstm_models/bidirec_model_0')\n",
    "model_1 = load_model('./lstm_models/bidirec_model_1')\n",
    "model_2 = load_model('./lstm_models/bidirec_model_2')\n",
    "model_3 = load_model('./lstm_models/bidirec_model_3')\n",
    "model_4 = load_model('./lstm_models/bidirec_model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:31:24.766272Z",
     "start_time": "2018-03-25T17:07:00.076353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model DeepConvLSTM created\n",
      "Epoch 1/5\n",
      "12576/12576 [==============================] - 292s 23ms/step - loss: 0.5669 - acc: 0.7044\n",
      "Epoch 2/5\n",
      "12576/12576 [==============================] - 293s 23ms/step - loss: 0.5414 - acc: 0.7222\n",
      "Epoch 3/5\n",
      "12576/12576 [==============================] - 292s 23ms/step - loss: 0.5367 - acc: 0.7250\n",
      "Epoch 4/5\n",
      "12576/12576 [==============================] - 293s 23ms/step - loss: 0.5367 - acc: 0.7243\n",
      "Epoch 5/5\n",
      "12576/12576 [==============================] - 292s 23ms/step - loss: 0.5336 - acc: 0.7257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59cd956748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = y.shape[1]\n",
    "bidirec = bidirectional_lstm(num_classes)\n",
    "bidirec.fit(X, y, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:31:56.725271Z",
     "start_time": "2018-03-25T17:31:56.103455Z"
    }
   },
   "outputs": [],
   "source": [
    "bidirec.save('./lstm_models/bidirec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:41:51.956253Z",
     "start_time": "2018-03-25T17:41:26.166664Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:49:21.478682Z",
     "start_time": "2018-03-25T17:47:47.951619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1439/1439 [00:12<00:00, 115.65it/s]\n",
      "100%|██████████| 1440/1440 [00:23<00:00, 60.71it/s]\n",
      "100%|██████████| 1440/1440 [00:19<00:00, 75.38it/s]\n",
      "100%|██████████| 1440/1440 [00:27<00:00, 52.33it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./test.csv')\n",
    "test = feat_eng.add_fg(test, test=True)\n",
    "test = feat_eng.add_incremental_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:54:17.452236Z",
     "start_time": "2018-03-25T17:50:30.616691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test pivotation 1440/1441test table pivoted\n"
     ]
    }
   ],
   "source": [
    "df1 = test\n",
    "df1_tot = pd.DataFrame()\n",
    "for sec in range(1,1441):\n",
    "    print('\\r test pivotation %d/%d' % (sec, 1441), end='')\n",
    "    df_sec = df1[['ID']+[k for k in df1.columns if k not in ['ID'] and k.split('_')[1] == str(sec)]]\n",
    "    df_sec.columns = [k.split('_')[0] if k not in ['ID', 'time_step'] else k for k in df_sec.columns]\n",
    "    df_sec = df_sec.assign(time_step = sec)\n",
    "    df1_tot = pd.concat([df1_tot, df_sec])\n",
    "df1_tot = df1_tot.sort_values(['ID', 'time_step'])\n",
    "print('test table pivoted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:54:40.403128Z",
     "start_time": "2018-03-25T17:54:23.752702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test created\n"
     ]
    }
   ],
   "source": [
    "cols = ['score', 'offensive rebound', 'defensive rebound',\n",
    "        'offensive foul', 'defensive foul', 'assist', 'lost ball', \n",
    "        'steals', 'bad pass', 'block', 'miss', 'two pts', 'three pts', \n",
    "        'fg', 'total rebound', 'turnover', 'fga']\n",
    "\n",
    "df_X = df1_tot[df1_tot.time_step < 1441]\n",
    "X_test = []\n",
    "#y = df_X.groupby('ID').mean()['label'].values\n",
    "#y = y.reshape((len(y), 1))\n",
    "for id_ in df1_tot.ID.unique():\n",
    "    X_test.append(df_X[df_X.ID == id_][cols].values)\n",
    "X_test = np.array(X_test)\n",
    "print('X_test created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:55:17.551572Z",
     "start_time": "2018-03-25T17:54:50.820056Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tot = bidirec.predict_proba(X_test)\n",
    "#X_tot.apply(round).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T18:10:03.298927Z",
     "start_time": "2018-03-25T18:08:49.853310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292461832061069"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = bidirec.predict_proba(X)\n",
    "np.mean(np.round(X_) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T17:56:38.887897Z",
     "start_time": "2018-03-25T17:56:38.757940Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = pd.DataFrame()\n",
    "Y['ID'] = test['ID']\n",
    "Y['label'] = np.round(X_tot)\n",
    "Y.to_csv('pred_bidirection_lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-25T16:08:35.975Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pred = pd.DataFrame(np.argmax(y_pred, axis=1), columns= ['label'])\n",
    "#Pred['ID'] = id_test\n",
    "#Pred[['ID', 'label']].to_csv('pred_v3.csv', index=False)\n",
    "#print('Prediction exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
